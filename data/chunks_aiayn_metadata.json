[
  {
    "section": "Introduction",
    "subsection": null,
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "24cfc352-1f43-4184-92a1-8180eca6dec5",
    "full_path": "Introduction"
  },
  {
    "section": "Background",
    "subsection": null,
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "381355db-8d61-4dbc-90ed-69171d4818d1",
    "full_path": "Background"
  },
  {
    "section": "Model Architecture",
    "subsection": null,
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "1436ce3f-8cc2-433e-aa13-649f16bab711",
    "full_path": "Model Architecture"
  },
  {
    "section": "Model Architecture",
    "subsection": "Encoder and Decoder Stacks",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "ff3be684-a39d-4dff-889b-a7651d7160d5",
    "full_path": "Model Architecture > Encoder and Decoder Stacks"
  },
  {
    "section": "Model Architecture",
    "subsection": "Attention",
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "0812f05f-340c-4151-a7c6-1820d786eb83",
    "full_path": "Model Architecture > Attention"
  },
  {
    "section": "Model Architecture",
    "subsection": "Attention",
    "subsubsection": "Scaled Dot-Product Attention",
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "0a334212-dc67-4c53-90f3-ea5aca95794b",
    "full_path": "Model Architecture > Attention > Scaled Dot-Product Attention"
  },
  {
    "section": "Model Architecture",
    "subsection": "Attention",
    "subsubsection": "Multi-Head Attention",
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "60aaaf21-da09-4601-b07f-7d9847d648a1",
    "full_path": "Model Architecture > Attention > Multi-Head Attention"
  },
  {
    "section": "Model Architecture",
    "subsection": "Attention",
    "subsubsection": "Applications of Attention in our Model",
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "962285ec-0327-40a8-9261-601714d2047f",
    "full_path": "Model Architecture > Attention > Applications of Attention in our Model"
  },
  {
    "section": "Model Architecture",
    "subsection": "Position-wise Feed-Forward Networks",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "282d8438-7fa2-4dcb-9361-f4e782e75598",
    "full_path": "Model Architecture > Position-wise Feed-Forward Networks"
  },
  {
    "section": "Model Architecture",
    "subsection": "Embeddings and Softmax",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "2c202111-4efa-4362-839e-e9160297a265",
    "full_path": "Model Architecture > Embeddings and Softmax"
  },
  {
    "section": "Model Architecture",
    "subsection": "Positional Encoding",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "4956c79a-1749-4c39-a937-a0a76a3edd71",
    "full_path": "Model Architecture > Positional Encoding"
  },
  {
    "section": "Why Self Attention",
    "subsection": null,
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "771c8c47-c45b-4888-82b3-0c30068d92c3",
    "full_path": "Why Self Attention"
  },
  {
    "section": "Why Self Attention",
    "subsection": "Computational Performance and Path Lengths",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "3f98b9f5-6013-4fdf-bac7-aa61b4521f1f",
    "full_path": "Why Self Attention > Computational Performance and Path Lengths"
  },
  {
    "section": "Why Self Attention",
    "subsection": "Unfiltered Bottleneck Argument",
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "11af348c-87a3-4f05-9b55-5de6a7d46284",
    "full_path": "Why Self Attention > Unfiltered Bottleneck Argument"
  },
  {
    "section": "Training",
    "subsection": null,
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "d01a8d99-2fd2-46fc-92c2-3328b3c0d831",
    "full_path": "Training"
  },
  {
    "section": "Training",
    "subsection": "Training Data and Batching",
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "53abb1e8-9ce7-4426-93d2-ec3b5afb77af",
    "full_path": "Training > Training Data and Batching"
  },
  {
    "section": "Training",
    "subsection": "Hardware and Schedule",
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "dbbe58e3-e1d0-44d1-a226-23a0c8f91fc7",
    "full_path": "Training > Hardware and Schedule"
  },
  {
    "section": "Training",
    "subsection": "Optimizer",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "296260ce-3bbd-4fae-b832-1e17fe6f81e6",
    "full_path": "Training > Optimizer"
  },
  {
    "section": "Training",
    "subsection": "Regularization",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "4da7c4e3-c2c4-4079-ace9-c42789854c8e",
    "full_path": "Training > Regularization"
  },
  {
    "section": "Results",
    "subsection": "Machine Translation",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "e4c2a4fa-6896-4ff5-ad20-0b92dd7057d6",
    "full_path": "Results > Machine Translation"
  },
  {
    "section": "Results",
    "subsection": "Model Variations",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "6ab996fe-2ddb-48ba-8003-8c2278e9e1a1",
    "full_path": "Results > Model Variations"
  },
  {
    "section": "Results",
    "subsection": "English Constituency Parsing",
    "subsubsection": null,
    "contains_math": 1,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "d3858106-5c0e-41ca-8438-372bfd791271",
    "full_path": "Results > English Constituency Parsing"
  },
  {
    "section": "Conclusion",
    "subsection": null,
    "subsubsection": null,
    "contains_math": 0,
    "paper_title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "\u0141ukasz Kaiser",
      "Illia Polosukhin"
    ],
    "year": 2017,
    "organization": "Google Brain",
    "chunk_id": "68db728c-76b9-46c9-aa41-c891e98c68a8",
    "full_path": "Conclusion"
  }
]